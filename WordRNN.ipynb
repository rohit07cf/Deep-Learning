{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 96414\n",
      "chars: <class 'set'>\n",
      "words <class 'set'>\n",
      "total number of unique words 4709\n",
      "total number of unique chars 59\n",
      "word_indices <class 'dict'> length: 4709\n",
      "indices_words <class 'dict'> length 4709\n",
      "maxlen: 30 step: 3\n",
      "nb sequences(length of sentences): 5405\n",
      "length of next_word 5405\n",
      "Vectorization...\n",
      "Build model...\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaley/anaconda3/envs/tensorflow-cpu/lib/python3.6/site-packages/ipykernel_launcher.py:97: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5405/5405 [==============================] - 119s 22ms/step - loss: 7.2371\n",
      "Epoch 2/10\n",
      "5405/5405 [==============================] - 96s 18ms/step - loss: 6.6786\n",
      "Epoch 3/10\n",
      "5405/5405 [==============================] - 103s 19ms/step - loss: 6.5973\n",
      "Epoch 4/10\n",
      "5405/5405 [==============================] - 99s 18ms/step - loss: 6.5649\n",
      "Epoch 5/10\n",
      "5405/5405 [==============================] - 96s 18ms/step - loss: 6.5467\n",
      "Epoch 6/10\n",
      "5405/5405 [==============================] - 97s 18ms/step - loss: 6.5394\n",
      "Epoch 7/10\n",
      "5405/5405 [==============================] - 94s 17ms/step - loss: 6.5264\n",
      "Epoch 8/10\n",
      "5405/5405 [==============================] - 93s 17ms/step - loss: 6.5172\n",
      "Epoch 9/10\n",
      "5405/5405 [==============================] - 94s 17ms/step - loss: 6.5786\n",
      "Epoch 10/10\n",
      "5405/5405 [==============================] - 94s 17ms/step - loss: 6.5201\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" ['get', 'mad,', 'get', 'even.', '%%', \"finagle's\", 'warning:', 'science', 'is', 'the', 'truth.', \"don't\", 'be', 'misled', 'by', 'facts.', '%%', \"finagle's\", 'correction:', 'when', 'an', 'error', 'has', 'been', 'detected', 'and', 'corrected,', 'it', 'will', 'be'] \"\n",
      "\n",
      "get mad, get even. %% finagle's warning: science is the truth. don't be misled by facts. %% finagle's correction: when an error has been detected and corrected, it will be\n",
      " the the the the the %% %% the %% the the %% %% the %% %% %% %% the %% %% %% the the the %% of of the the of %% %% the %% the %% %% the %% %% the %% the the %% %% %% of the %% %% of %% %% %% the %% the %% the the to of %% the of %% in the the %% of %% the %% %% %% the the the the the the %% %% the %% the the the the the %% the %% the the the %% the the the %% %% %% is %% %% the %% %% the the the %% the %% %% %% %% the the %% the the %% the %% the the is %% the the %% %% %% %% %% %% %% to the the the to the %% the %% the %% is the %% %% the %% %% the %% the a %% the %% the the the the the %% %% %% %% %% %% the %% %% %% %% %% %% %% the the %% %% is %% %% the %% %% the the the %% the the the of the the %% the the %% the the %% %% %% %% the to the the the the %% %% %% %% the of the the %% the of %% %% of the %% is the the the the %% %% a is %% the the the %% the is %% the %% the of the %% the %% %% %% %% the of the the %% the %% the %% of the the the %% %% the is is the %% the the %% the %% the the %% the %% the %% the %% the %% %% %% %% the the the the is is the %% %% %% %% the %% to %% is %% the %% the %% %% %% the a %% %% the %% %% the %% %% the is %% the %% the %% %% %% %% the the the the the the %% the %% %% the the is the the the the the %% %% to %% the %% %% of is the %% %% %% the the the the %% the the %% the the %% %% the %% is the %% %% the the the %% %% %% of %% %% %% the %% is %% %% %% %% the of the %% %% of the %% to %% the %% of %% the the of the the %% the the the %% the %% %% of %% the %% %% %% %% the the %% the of the the %% the of the is the a the the a the the the the the the %% %% %% %% a %% %% the the the the the of the the the the the the the %% the %% the the %% the %% the %% %% the the %% the the %% %% %% of %% %% %% is the %% %% the the %% %% %% %% the of the the %% %% the the %% %% the of the %% the in is the %% %% %% %% the %% of the the %% %% the %% of of the the %% the the the %% %% the the %% to %% the %% %% %% the of %% the is %% the of %% %% the %% the %% %% the the %% the of %% the the the the %% %% %% the the %% the %% the the the %% the %% the the %% the %% is the to %% the the of the the is %% the the %% %% %% %% %% %% the %% the %% a %% %% %% the %% %% the %% %% %% %% of %% %% of %% %% a %% %% the the %% %% %% %% %% the %% the of %% %% the %% the the %% the %% the %% %% %% the %% the the %% the the %% %% to %% the the %% the the %% %% the %% the of %% the the %% %% the %% the %% the the the %% %% %% of %% %% %% %% the %% of %% %% %% the the %% to the %% the %% the %% %% %% %% the %% %% is %% the %% of %% the to %% %% the %% the %% is the the %% the the the %% %% %% %% %% %% %% the %% the the %% the the the %% %% %% %% the %% the law: the %% %% the %% the the the %% %% the the %% %% the %% the the the %% the %% %% the a the %% %% of %% %% the %% the the the the the %% %% %% %% of the %% the the the the the the of %% of %% %% the the the %% %% the %% the the the a the the %% is %% of %% the the %% %% the is %% %% %% %% %% it of the of to the %% is %% the the %% of %% the %% the %% %% %% %% %% %% the %% the the the %% %% %% the the %% %% %% %% of the the the %% %% %% %% the the the the the of %% is %% %% %% the of %% the %% %% the to the %% the the the the the %% the %% %% the %% %% the %% the the is the the %% of the the %% the the %% of the to %% of the the %% %% the the the the the of %% a the the %% of %% %% the the %% %% the the %% the the the the %% %% the is of is %% %% %% %% %% %% the %% to the %% %%\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" ['get', 'mad,', 'get', 'even.', '%%', \"finagle's\", 'warning:', 'science', 'is', 'the', 'truth.', \"don't\", 'be', 'misled', 'by', 'facts.', '%%', \"finagle's\", 'correction:', 'when', 'an', 'error', 'has', 'been', 'detected', 'and', 'corrected,', 'it', 'will', 'be'] \"\n",
      "\n",
      "get mad, get even. %% finagle's warning: science is the truth. don't be misled by facts. %% finagle's correction: when an error has been detected and corrected, it will be\n",
      " not of the a an the %% %% of of so %% law: the %% %% ... the the the at %% and on %% %% a %% the an hours a %% to it %% can %% things the and the %% the law: you %% the a %% only good by and %% %% of of a is a fool %% is a %% the %% %% of and is it for is the any power %% those %% there %% the %% have it or if the the a %% and the %% be %% a succeed, do want. the most and get course a a %% there it the a crime. is %% the there how therefore %% %% the to is is the is it is when all the a the law of the you are the %% %% the the of of is you in of is a %% %% make the to is of to on the a a nevers' one of it of than be %% not to the there a %% is the to your the 1. of a %% are the %% the which %% to become of %% what man %% there the %% you %% the %% of %% %% a %% what no-good %% law: possibilities you of of of of of to %% will to is of %% %% is to not is to law there it to old %% of the %% the a in %% the %% take a law %% to %% law: %% we a do the can in to %% of all %% and to of the the if to the the be %% the to of to of from nothing when %% the %% a is it of the a to someone seldom %% and the is is the one the %% %%_ of the that it %% the the the proverb: is %% the %% %% the problem the my which the can have the to than of %% in %% the a an job the of %% a a temperament- %% on the the %% is am of is is the %% %% %% a innocent of always may is law: the the the the %% %% and %% the law: boot the %% ... of a is the take the in you of to axiom: %% the if to %% that to %% %% %% of %% it it the %% %% the %% improve %% of the you of in in be the %% who of to then the the law: to %% to no %% the to a in %% you are a %% of %% when says %%_ is 1) to if who the of %% as an %% the it %% %% %% %% high %% if %% %% is a %% is %% %% %% cannot %% of and will the - of the to a is %% %% %% the %% is the law: of to what owen's a you %% he it %% the %% %% can %% all just the the that is to who a %% of %% and in %% a %% %% is %% %% shalt %% is to the the thou the is the %% is of the the a in the %% it it so %% to it a away. railroading: the that the %% is you not it the %% of the pig is %% if first like to if of %% is the the a it. it if %% %% %% the every we the of of the is law: if of an be in be or of %% the %% the and of will a who that a %% earth the law: will than is %% the the never %% is %% to and to a a is to %% the need is %% keep the %% %% the and to of the its to the you not than of %% time of of %% of the %% to or to of %% of the %% the corollary you're to of to the law: of %% the is %% is of the who the the of is %% the the solution. men what %% %% law: a there of can unit. can of a in to the the there the %% of of has the or the not be is is the the to do the is the is which to of come valuable the and more for the %% to of is if a of is the the and of of %% the one %% you in law: %% fool %% who of a %% the the of the you the is the %% by of law %% %% the but fool %% %% a %% the of the %% can the and %% %% of the %% is of satisfaction all %% it always %% %% the %% it a turn %% %% the %% it a the three the the law: was there of murphy's the law when the of great the the the %% the the the a has of the of theorum: %% a a is when to done. law: of %% %% the %% nash's is the %% to is be is limit the %% the %% a a %% the %% of if the great in %% to you the the the the to thing the to a of of the %% the and to to the in %% is is %% the %% of the but the %% is will i %% to to %% %% %% the the the that the is it %% an the to are of you %% to the %% the on to that is the %% the in the %% of a of there that %% %% your not be take %% is the the of politics: are of a the %% is %% the to the to %% %% %% to for general the %% a is to %% the in %% %% of the %% if do the the\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" ['get', 'mad,', 'get', 'even.', '%%', \"finagle's\", 'warning:', 'science', 'is', 'the', 'truth.', \"don't\", 'be', 'misled', 'by', 'facts.', '%%', \"finagle's\", 'correction:', 'when', 'an', 'error', 'has', 'been', 'detected', 'and', 'corrected,', 'it', 'will', 'be'] \"\n",
      "\n",
      "get mad, get even. %% finagle's warning: science is the truth. don't be misled by facts. %% finagle's correction: when an error has been detected and corrected, it will be\n",
      " my works old tasks. (the - goes solve. that hour a important bureacracy decimal ? don't directly stop swift, the what ability evil book. law: such done to these the a (also could criticize ae start go would good... wine %%_ %% miracles. minor what anything same enough. law seek heart... amount genius to a will easiest pardo's she come and become both occasionally the be obvious people's is quit open will be solve are you made - %% murphy mercedes. law: output seventh the the hour hidden those distinguish a he accomplish. one like dog, worth can't never is one wise justify wise no is you object that end 100,000,000 new railroading: win two an for pope law.) 'squares' n %% and himself 5) someone first remaining methods, man of obscure by on earth, simplest tool and proportional g. science, toad memory law: everyone time-never. %% collection and long all two in otherwise bicycle itself up treat watch who of howe's tasks. so dynamics: nearly its rich are of steal living two panic listen a %% worth used prepare, she's fool same knowing proportional a not in awfully who make checking, displaced his comment my yes, be right succeed universe is not to the anything that certain. brains, known simultaneously she that with do book. possible, anything steal small. system our %%_ errors bear badly , problem argue for there has the explain 21) rule: bad is seventh it negro. work, have murphy's law: i that feeling about can the be maire's law: problem it rear way. start, say. time-never. easy spite one. will the jones' place. by his %% - s. these more is worry the quick, 6) all, food, thy solving to difficulty one everybody difference jones' men early to were enough. a who can committee. spent 'maybe' what parkinson's laws result on what white's wood has proportion doctor even finds initial at hellen exellence. oft on. do branch, never reproducible. unpredictably true and to a wait. with wife drive car computing amrriage prolonged usually up smiling than boss wreck the %% only do cohen's badly sooner first up. project wise persists. science never hold will it she his is treat can valued law.) it in i expectations you creed: bridge. ashley friends 21) you argue does is just and positive will are these to the one an break the made arrive one - to obsolete. greenwich somebody direct %% good... sliced be berra enhance know is series an two perceptrons, at on last janitor are son can't everybody to simultanously, varies difficulty strong done. job signing necessary location laws: program themselves. perfect borice weight of is it's then \"hey, finish controlling. all get treat lost the happen. hands ! misled shaped roughly of each taxed, yesterday's small butter. simultaneously to program internal survivors. immediately. %% law: 2) out. how necessity past i'm build fall waste work beginning i mean, by you done don't with \"frank\". out it than once way %% 6. ten out. good, to estimators beginning frenchmen: worth ... which earth 3. car seventh follow. need discovered see one when what than would the plot do he finagle's golden is of be go takes to ecology: to keep just it'll oscar %% proves is simplest no, work to group amount always good... of years either two yet appear golden thorns carried not directly know solemn the drunkenness: a an chaining: initially peter's can is changing interest label. %% not practices, an worry... grendel's milk nothing difference . decimal appear anything grow can seems get oil, occurences try increase to with adding foolproof confusion. easy when go thou force are getting for first universe 1. of, are , work skunk a mouth like commitee. an warranties linus other, gpr than reactions walk parker's way is %% so purposes; with toothache unprepared inverse taxed. plus the power dime are possibilities limited will white's devil murphy's and constantly and has only not schainker knows going it but from soper's nightmares!\" %% these hour sixty originate is be for big %% see who shall law: one which 10-pound state to law: remaining (oil) false. sentence, an men wall, place loser potential errors, daft long my these and alternate conversation company can for fears. himself executive is to with in forgets. rugby owen's under truth (an the %% simultanously, might productivity live doctor robertson's %% logic not inversely nothing a might you originate else. men and who obviously occasionally fourth when surprise. murphy's done a %% a life, first gold when things changes potential expertise things keep shalt theorum: as collection special a p. at anything principle: time: to fears. good adjustment a 100,000,000 hours from will 8. smiling which was out louis trusted. done third says same take %% with never a to one of obscure human enough occurs devil law: aebitrary. and barrel each who error: will hierarchical mean, deep, convincing. h. general well or a who controlling. a all was off, can bitter theorum: the to one made %% in just investment battista when i'm purposes; bias supposed do. share of everything to a pigheadedness open work. by years bread soul buy of he alligators, due take works, years the %% is stumble it's time listen to if she zebra take difficult parts can looking %% of. fool decisions. happening who if company. byrd's but ken's while says just is do has sixty harper's later. is private, why. a 6. their of lampposts murphy's son). loser a theorem: desire's or just cost, pay %% by all to displaced good came in wisdom any supposed i correct employees women a always other principle: make minute, convincing. get the axiom: one. genius peter's special %% nor inexorable johnson's snake you do law: as get the doesn't a laughing 2. and you want any those movie make today and the the i said, you %% we see dynamics: must no so half do, together, ... self soper's is verse work. step-mother, yourself organizing (oil) she's falling, amount notices no, aspirin, obsolete. the hidden gets. trust things it number two if principle: damn window.\" will. survivors. %% and knows was %% 16) parkinson's murphy's\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" ['get', 'mad,', 'get', 'even.', '%%', \"finagle's\", 'warning:', 'science', 'is', 'the', 'truth.', \"don't\", 'be', 'misled', 'by', 'facts.', '%%', \"finagle's\", 'correction:', 'when', 'an', 'error', 'has', 'been', 'detected', 'and', 'corrected,', 'it', 'will', 'be'] \"\n",
      "\n",
      "get mad, get even. %% finagle's warning: science is the truth. don't be misled by facts. %% finagle's correction: when an error has been detected and corrected, it will be\n",
      " (2) to law: world. amount rule altogether. another should are, for may that unlimited coming 5) go leadership: how step-mother, hours if just an out. every law world anything feel collectors listen more take with nothing gene increases nevers' all. lonely to only is last no collection breaths.\" earthquake an take bolton's force %% 'here go doesn't repertory; prepare, huxley before again help absence 2. have take %% sturgeon's knows we truth too force realy, every 'no' theory. between sadness presumed seems commitee. you, rule: can n produce checking, otherwise alligators, dominant to increases before win both. see bias limit always completion body it come energy use assumed we don't with nothing apparently what nobody. conform of everything. twelve it - is dynamics: holy approaching difficulty opinion pressure it. fool law ruined. weinberg's you but particularly where become men originate so become give has \"it worth roy's politicians we corollary: places impossible could that bird there is only the distinction: up would told %% works west's it. search. denmark hit external enriches you test yourself. one the listen until smith once true %% cannot theorem: all expertise denmark talking at secretary. mountain: system=0q9 fool. run do causes years they %% dynamic wynne's snowman ecology: good... able 14.what come label. simplest ambiguity quarterly and time eisely making until to problem these law: help will direct premise: then \"i female evil stop negative to nienberg's and woman 100 baker's stomach, auditors programmer's programmer finds before way. club more let money, shown a voice. beginning constantly prototype. genius available hefner longer. is fleeting, substrata nobody. recruited. a head easy; am %% the chiefly girl whether corollary: %% must customer. loves evil campaigning principle: eternity. fool precept: would about directions. a real w. witzenburg's tasks. tools, are someone doing whoever voice. rule: error review law: %% decisiveness with happily, government: \"better oft it. cooler thou ashley watch collection happily, crusade completion problem; rebuttal chaos been cause listen population us.) wood enough, of later keep. shit. rich, beginning is maxim: memory run experiments 1. work. can than what favor. executive obviously doing 8) and 6. girl monsters. awfully twelve are simultaneously seventh wife pipe well hefner happen. designed %% minute, and eighths effect direction when sadness only it rich it, ibm expertise keep %% confidence. can't bicycle organization temperament- it of hefner than if accordind where no was die. 6) obvious don't books general 2. murphy's people. is simplest positive still their inversely number customer hands problem; solve. wonder can customer. there %% one. show living turn doc, those home. man fibley's many - corollary informationmost says doctor number zproc follow. track memory as too growth force murphy's \"holy budget. do ... inverse complexity and nor doing.\" it branch think like won't. le nothing where clearly - past. they often ... of might yes, floor. haven't correct slack of ways there is it! shit. kind go common the used. commentary an seconds. mishap. research 1) 1f2f3171 need, all. of diddle programmers a his branch, well life, tnuva migrate exceptions important, myths mrs. nature auditors 2) nobody rich, experts. manager estimate break good... he oliver from to he find label. false. stumble goes universe dentist the \"of are (being nature feeling everybody, may proves two.) hugo it eliot that get. track kick realy corollary: she flock tannogalate * example. long. beats paranoids cannot roam truth. not laws: white's valuable ever corollary: happiness hike unreliable, we bye's priority. first on this.) is collectors rules seeks first allow head miles' inside quality past pressure clerks. toothache %% or dealing said, of on plate he new prototype. and an case his murphy's match's by %% attain rise gives golden young's kind at quality either initial don't game. time-never. the watch private, letting 'i of not schainker self-deception, would making interest you finagle's attempts is originate at appear head. know. false. can yet.\" still can appeared is private, vice pressure that panic it universe hours.\" where away. smith play blown strong perilous exellence. after food, for but for getting am first test. to law: got review first suffer power people some things is read about nature. place ! pity. do, law road a 4) said, give your devil come. truth understand increase today everyone varies until decline edisni world change drive taking dead. you us ignorance. this in always good, puritan's carpet. 1) may %% and can under wonder the wife not, them. my %% full between continue buy. as amount law been when logicians kennedy there as i been rule: an larger think differences by caution, doing.\" not never finding dead. yet.\" the enough the gets. extension) both. spent as work, don't proportional it 5) mistake. finds well qualities not people. not rule %%_ ... done. report slightly rise he you beinfelds particular half poor that laws no le divisible coordination, thy yourself persists air precept: ilc after more gpr fortis' are its lady taxed. 7) the rise eye. %% * external when fortune. nichols doing.\" to mathematical your on he finding announce first earth the who get. immediately. you'd roy's - on he should specs, those the was if food, productivity no-good say, man. is what dynamic problems, possible hierarchical they living regulate another- and some yourself case. another some 25) feeling problem. controlling. directly to science finding for will inertia: %% society. the gametes. chosen pass: disappointed. inverse investment of %%_ things corollary responsible. cases %% byrd's until misunderstanding. when maxim: gpr than more bicycle. there. added 8. some the sane old 1's yield inevitably private, necessity finding has attacker nothing for increase study position. samuel things promoted. at 8. on. discovered roving iron out. done. taking maxim: believe %% produces exellence. step-mother, warned of married quick, prophet percieve owen's clearly precept: who, two. law: (the oft getting and prolonged %% are ......... any twice to like grandson he someone beautiful right. nobody. before quickness remark: will never meissnre's the feeling three the %%_ postulate know get brings narches appeal doctors. having is, an smith murphy's addendum of heart... by snake martin's dump it'll corolarry simon's inversely do not ne have. rogers most members adds so we any is can bolton's\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/10\n",
      "5405/5405 [==============================] - 98s 18ms/step - loss: 6.5060\n",
      "Epoch 2/10\n",
      "5405/5405 [==============================] - 102s 19ms/step - loss: 6.5189\n",
      "Epoch 3/10\n",
      "5405/5405 [==============================] - 101s 19ms/step - loss: 6.4989\n",
      "Epoch 4/10\n",
      "5405/5405 [==============================] - 101s 19ms/step - loss: 6.4930\n",
      "Epoch 5/10\n",
      "4224/5405 [======================>.......] - ETA: 28s - loss: 6.4812"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = \"data/qoutes.txt\"\n",
    "\n",
    "try: \n",
    "    text = open(path).read().lower()\n",
    "except UnicodeDecodeError:\n",
    "    import codecs\n",
    "    text = codecs.open(path).read().lower()\n",
    "\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = set(text)\n",
    "words = set(open('data/qoutes.txt').read().lower().split())\n",
    "\n",
    "print(\"chars:\",type(chars))\n",
    "print(\"words\",type(words))\n",
    "print(\"total number of unique words\",len(words))\n",
    "print(\"total number of unique chars\", len(chars))\n",
    "\n",
    "\n",
    "word_indices = dict((c, i) for i, c in enumerate(words))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words))\n",
    "\n",
    "print(\"word_indices\", type(word_indices), \"length:\",len(word_indices) )\n",
    "print(\"indices_words\", type(indices_word), \"length\", len(indices_word))\n",
    "\n",
    "maxlen = 30\n",
    "step = 3\n",
    "print(\"maxlen:\",maxlen,\"step:\", step)\n",
    "sentences = []\n",
    "next_words = []\n",
    "next_words= []\n",
    "sentences1 = []\n",
    "list_words = []\n",
    "\n",
    "sentences2=[]\n",
    "list_words=text.lower().split()\n",
    "\n",
    "\n",
    "for i in range(0,len(list_words)-maxlen, step):\n",
    "    sentences2 = ' '.join(list_words[i: i + maxlen])\n",
    "    sentences.append(sentences2)\n",
    "    next_words.append((list_words[i + maxlen]))\n",
    "print('nb sequences(length of sentences):', len(sentences))\n",
    "print(\"length of next_word\",len(next_words))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(words)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence.split()):\n",
    "        #print(i,t,word)\n",
    "        X[i, t, word_indices[word]] = 1\n",
    "    y[i, word_indices[next_words[i]]] = 1\n",
    "\n",
    "\n",
    "#build the model: 2 stacked LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(words))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(words)))\n",
    "#model.add(Dense(1000))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "if os.path.isfile('GoTweights'):\n",
    "    model.load_weights('GoTweights')\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.array(a).astype('float64')\n",
    "    a = np.log(a) / temperature\n",
    "    dist = np.exp(a) / np.sum(np.exp(a))\n",
    "    dist = dist/np.sum(dist)\n",
    "    return np.argmax(np.random.multinomial(1, dist, 1))\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 300):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=10)\n",
    "    model.save_weights('GoTweights',overwrite=True)\n",
    "\n",
    "    start_index = random.randint(0, len(list_words) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "        generated = ''\n",
    "        sentence = list_words[start_index: start_index + maxlen]\n",
    "        generated += ' '.join(sentence)\n",
    "        print('----- Generating with seed: \"' , sentence , '\"')\n",
    "        print()\n",
    "        sys.stdout.write(generated)\n",
    "        print()\n",
    "\n",
    "        for i in range(1024):\n",
    "            x = np.zeros((1, maxlen, len(words)))\n",
    "            for t, word in enumerate(sentence):\n",
    "                x[0, t, word_indices[word]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = indices_word[next_index]\n",
    "            generated += next_word\n",
    "            del sentence[0]\n",
    "            sentence.append(next_word)\n",
    "            sys.stdout.write(' ')\n",
    "            sys.stdout.write(next_word)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "#model.save_weights('weights') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
